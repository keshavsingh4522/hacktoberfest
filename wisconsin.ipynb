{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.data', header=None)\n",
    "df.loc[:, 6].replace(['?'], 1, inplace=True)\n",
    "df.loc[:, 6] = pd.to_numeric(df.loc[:, 6])\n",
    "df.drop(axis = \"rows\", labels = df.index[df.duplicated()], inplace=True)\n",
    "df.apply(pd.to_numeric, errors='ignore')\n",
    "rows = df.shape[0]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = df.loc[:,[1,2,3,4,5,6,7,8,9,10]]\n",
    "Y = df.iloc[:,10]\n",
    "Y = Y.replace(4,0)\n",
    "Y = Y.replace(2,1)\n",
    "# print(Y)\n",
    "np.random.seed(9)\n",
    "arr_rand = np.random.rand(X.shape[0])\n",
    "split = arr_rand < np.percentile(arr_rand, 70)\n",
    "X_train = X[split]\n",
    "Y_train = Y[split]\n",
    "X_test =  X[~split]\n",
    "Y_test = Y[~split]\n",
    "\n",
    "\n",
    "X_train.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(483, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOGISTIC REGRESSION MULTIVARIATE GRADIENT DECENT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def logistic(z):\n",
    "    return (1 + np.exp(-z))**(-1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "n_iter = 5000\n",
    "lr = 0.01"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "length = X_train.shape[0]\n",
    "X_input = X_train.iloc[:,0:9]\n",
    "X_input.insert(9, \"faltu\", [1]*len(X_train), True)\n",
    "X_input_test = X_test.iloc[:,0:9]\n",
    "X_input_test.insert(9, \"faltu\", [1]*len(X_test), True)\n",
    "\n",
    "beta = np.random.uniform(low = -10, high =10, size = 10)\n",
    "for _ in range(n_iter):\n",
    "    p = logistic(X_input@beta)\n",
    "    gradient = X_input.T@(Y_train-p)\n",
    "    beta += lr*gradient \n",
    "\n",
    "modi = np.array(logistic(X_input@beta))\n",
    "count1 = 0 \n",
    "count2 = 0\n",
    "\n",
    "for i in range(len(modi)):\n",
    "    if(modi[i]>=0.5):\n",
    "        modi[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modi[i] = 0\n",
    "        count2 = count2+1\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Training data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_train, modi)*100)\n",
    "\n",
    "modv = np.array(logistic(X_input_test@beta))\n",
    "for i in range(len(modv)):\n",
    "    if(modv[i]>=0.5):\n",
    "        modv[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modv[i] = 0\n",
    "        count2 = count2+1\n",
    "print(\"Test data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_test, modv)*100)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy:-\n",
      "95.23809523809523\n",
      "Test data accuracy:-\n",
      "96.61835748792271\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOGISTIC UNIVARIATE GRADIENT DECENT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "Xn_iter = 5000\n",
    "lr = 0.01"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_uni = X_train.iloc[:,2]\n",
    "X_dummied = np.zeros((X_train.shape[0], 2))\n",
    "X_dummied[:,1] = 1\n",
    "X_dummied[:,0] = X_uni \n",
    "\n",
    "X_uni = X_test.iloc[:,2]\n",
    "X_dummied_test = np.zeros((X_test.shape[0], 2))\n",
    "X_dummied_test[:,1] = 1\n",
    "X_dummied_test[:,0] = X_uni\n",
    "\n",
    "beta = np.random.uniform(low = -10, high =10, size = 2)\n",
    "for _ in range(n_iter):\n",
    "    p = logistic(X_dummied@beta)\n",
    "    gradient = X_dummied.T@(Y_train-p)\n",
    "    beta += lr*gradient \n",
    "modi = np.array(logistic(X_dummied@beta))\n",
    "count1 = 0 \n",
    "count2 = 0\n",
    "\n",
    "for i in range(len(modi)):\n",
    "    if(modi[i]>=0.5):\n",
    "        modi[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modi[i] = 0\n",
    "        count2 = count2+1\n",
    "from sklearn import metrics\n",
    "print(\"Training data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_train, modi)*100)\n",
    "\n",
    "modv = np.array(logistic(X_dummied_test@beta))\n",
    "for i in range(len(modv)):\n",
    "    if(modv[i]>=0.5):\n",
    "        modv[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modv[i] = 0\n",
    "        count2 = count2+1\n",
    "print(\"Test data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_test, modv)*100)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy:-\n",
      "89.23395445134575\n",
      "Test data accuracy:-\n",
      "94.20289855072464\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NAIVE BAYES UNIIVARIATE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "b_p = 0.655\n",
    "m_p = 0.345"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "r_b = X_train.loc[X_train.iloc[:,9] == 2] \n",
    "r_m = X_train.loc[X_train.iloc[:, 9] == 4]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "Y_pred = []\n",
    "Y_pred_tes = []\n",
    "\n",
    "benign_column = r_b.iloc[:, 2]\n",
    "malignant_column = r_m.iloc[:, 2]\n",
    "b_mean = np.mean(benign_column)\n",
    "b_standard = np.std(benign_column)\n",
    "m_mean = np.mean(malignant_column)\n",
    "m_standard = np.std(malignant_column)\n",
    "\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    pB = b_p\n",
    "    pM = m_p\n",
    "    value = X_train.iat[i,2]\n",
    "    pB*= 1/(b_standard * np.sqrt(2 * np.pi)) * np.exp( - (value - b_mean)*2 / (2 * b_standard*2))\n",
    "    pM *= 1/(m_standard * np.sqrt(2 * np.pi)) * np.exp( - (value - m_mean)*2 / (2 * m_standard*2))\n",
    "    if(pB>=pM):\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)\n",
    "print(\"Training data accuracy:-:\", metrics.accuracy_score(Y_train, Y_pred)*100)\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    pB = b_p\n",
    "    pM = m_p\n",
    "    value = X_test.iat[i,2]\n",
    "    pB*= 1/(b_standard * np.sqrt(2 * np.pi)) * np.exp( - (value - b_mean)*2 / (2 * b_standard*2))\n",
    "    pM *= 1/(m_standard * np.sqrt(2 * np.pi)) * np.exp( - (value - m_mean)*2 / (2 * m_standard*2))\n",
    "    if(pB>=pM):\n",
    "        Y_pred_tes.append(1)\n",
    "    else:\n",
    "        Y_pred_tes.append(0)\n",
    "print(\"Testing data accuracy:-:\", metrics.accuracy_score(Y_test, Y_pred_tes)*100)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy:-: 91.7184265010352\n",
      "Testing data accuracy:-: 93.23671497584542\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MULTIvariate Naive "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def pro(mu, sigma, x):\n",
    "    return 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)*2 / (2 * sigma*2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "b_muu = []\n",
    "m_muu = []\n",
    "b_standard = []\n",
    "sigma_malignant = []\n",
    "for c in r_b:\n",
    "    MEAN = np.mean(r_b[c].values)\n",
    "    b_muu.append(MEAN)\n",
    "\n",
    "    SIGMA = np.std(r_b[c].values)\n",
    "    b_standard.append(SIGMA)\n",
    "\n",
    "\n",
    "for c in r_m:\n",
    "    MEAN = np.mean(r_m[c].values)\n",
    "    m_muu.append(MEAN)\n",
    "\n",
    "    SIGMA = np.std(r_m[c].values)\n",
    "    sigma_malignant.append(SIGMA)\n",
    "\n",
    "sigma_malignant.pop()\n",
    "\n",
    "\n",
    "print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    pM = m_p\n",
    "    pB = b_p\n",
    "    for j in range(r_b.shape[1]-1):\n",
    "        value = X_train.iat[i, j]\n",
    "        pB *= pro(b_muu[j], b_standard[j], value)\n",
    "        pM *= pro(m_muu[j], sigma_malignant[j], value)\n",
    "    if(pB>=pM):\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)\n",
    "\n",
    "print(\"Training data accuracy:\", metrics.accuracy_score(Y_train, Y_pred)*100)\n",
    "\n",
    "Y_pred_tes = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    pM = m_p\n",
    "    pB = b_p\n",
    "    for j in range(r_b.shape[1]-1):\n",
    "        value = X_test.iat[i, j]\n",
    "        pB *= pro(b_muu[j], b_standard[j], value)\n",
    "        pM *= pro(m_muu[j], sigma_malignant[j], value)\n",
    "    if(pB>=pM):\n",
    "        Y_pred_tes.append(1)\n",
    "    else:\n",
    "        Y_pred_tes.append(0)\n",
    "\n",
    "\n",
    "print(\"Test data accracy:\", metrics.accuracy_score(Y_test, Y_pred_tes)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy: 96.06625258799171\n",
      "Test data accracy: 98.55072463768117\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MULTIVARIATE NEWTON"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_input = X_train.iloc[:,0:9]\n",
    "X_input.insert(9, \"faltu\", [1]*len(X_train), True)\n",
    "beta = np.random.uniform(low = -10, high =10, size = 10)\n",
    "y_hat = logistic(X_input@beta)\n",
    "y_hat = np.reshape(y_hat,-1)\n",
    "S = np.diag(y_hat*(1-y_hat))\n",
    "h = X_input.T@S\n",
    "H = np.dot(h,X_input)\n",
    "H = np.linalg.inv(H)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "n_iter = 3000\n",
    "\n",
    "for _ in range(n_iter):\n",
    "    p = logistic(X_input@beta)\n",
    "    gradient = X_input.T@(Y_train-p)\n",
    "    beta += H@gradient\n",
    "\n",
    "modi = np.array(logistic(X_input@beta))\n",
    "\n",
    "for i in range(len(modi)):\n",
    "    if(modi[i]>=0.5):\n",
    "        modi[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modi[i] = 0\n",
    "        count2 = count2+1\n",
    "\n",
    "print(\"Training data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_train, modi)*100)\n",
    "\n",
    "X_input_test = X_test.iloc[:,0:9]\n",
    "X_input_test.insert(9, \"faltu\", [1]*len(X_test), True)\n",
    "odv = np.array(logistic(X_input_test@beta))\n",
    "for i in range(len(modv)):\n",
    "    if(modv[i]>=0.5):\n",
    "        modv[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modv[i] = 0\n",
    "        count2 = count2+1\n",
    "print(\"Test data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_test, modv)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy:-\n",
      "89.02691511387164\n",
      "Test data accuracy:-\n",
      "94.20289855072464\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# logistic univariate using newton"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_uni = X_train.iloc[:,2]\n",
    "X_dummied = np.zeros((X_train.shape[0], 2))\n",
    "X_dummied[:,1] = 1\n",
    "X_dummied[:,0] = X_uni \n",
    "\n",
    "X_uni = X_test.iloc[:,2]\n",
    "X_dummied_test = np.zeros((X_test.shape[0], 2))\n",
    "X_dummied_test[:,1] = 1\n",
    "X_dummied_test[:,0] = X_uni\n",
    "\n",
    "beta = np.random.uniform(low = -10, high =10, size = 2)\n",
    "y_hat = logistic(X_dummied@beta)\n",
    "y_hat = np.reshape(y_hat,-1)\n",
    "S = np.diag(y_hat*(1-y_hat))\n",
    "h = X_dummied.T@S\n",
    "H = np.dot(h,X_dummied)\n",
    "H = np.linalg.inv(H)\n",
    "for _ in range(n_iter):\n",
    "    p = logistic(X_dummied@beta)\n",
    "    gradient = X_dummied.T@(Y_train-p)\n",
    "    beta += H@gradient \n",
    "modi = np.array(logistic(X_dummied@beta))\n",
    "count1 = 0 \n",
    "count2 = 0\n",
    "\n",
    "for i in range(len(modi)):\n",
    "    if(modi[i]>=0.5):\n",
    "        modi[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modi[i] = 0\n",
    "        count2 = count2+1\n",
    "from sklearn import metrics\n",
    "print(\"Training data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_train, modi)*100)\n",
    "\n",
    "modv = np.array(logistic(X_dummied_test@beta))\n",
    "for i in range(len(modv)):\n",
    "    if(modv[i]>=0.5):\n",
    "        modv[i] = 1\n",
    "        count1 = count1+1\n",
    "    else:\n",
    "        modv[i] = 0\n",
    "        count2 = count2+1\n",
    "print(\"Test data accuracy:-\")\n",
    "print(metrics.accuracy_score(Y_test, modv)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/_v/m854shsd2wq5xv3gt6_g6ns00000gn/T/ipykernel_8689/3234334488.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 + np.exp(-z))**(-1)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data accuracy:-\n",
      "82.81573498964804\n",
      "Test data accuracy:-\n",
      "87.43961352657004\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit"
  },
  "interpreter": {
   "hash": "ff94885aa2d97705a9dae03869c2058fa855d1acd9df351499300343e2e591a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}