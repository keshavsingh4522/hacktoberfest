{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Hand Written Digits\n",
    "\n",
    "In this notebook we will write a full end-to-end training process using gluon and MXNet. We will train the LeNet-5 classifier network on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mxnet import gluon, metric, autograd, init, nd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M5_DATA = Path(os.getenv('DATA_DIR', '../../data'), 'module_5')\n",
    "M5_IMAGES = Path(M5_DATA, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and the data and construct the dataloader\n",
    "\n",
    "* First, get the MNIST dataset from `gluon.data.vision.datasets`. Use\n",
    "* Don't forget the ToTensor and normalize Transformations. Use `0.13` and `0.31` as the mean and standard deviation respectively\n",
    "* Construct the dataloader with the batch size provide. Ensure that the train_dataloader is shuffled.\n",
    "\n",
    "<font color='red'>**CAUTION!**</font>: Although the notebook interface has internet connectivity, the **autograders are not permitted to access the internet**. Set the `root` parameter to `M5_IMAGES` when using a preset dataset. Usually, in the real world, we have internet access, so setting the `root` parameter isn't required (and it's set to `~/.mxnet` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import numpy as np\n",
    "def get_mnist_data(batch=128):\n",
    "    \"\"\"\n",
    "    Should construct a dataloader with the MNIST Dataset with the necessary transforms applied.\n",
    "    \n",
    "    :param batch: batch size for the DataLoader.\n",
    "    :type batch: int\n",
    "    \n",
    "    :return: a tuple of the training and validation DataLoaders\n",
    "    :rtype: (gluon.data.DataLoader, gluon.data.DataLoader)\n",
    "    \"\"\"\n",
    "    \n",
    "    def transformer(data, label):\n",
    "        data = data.flatten().expand_dims(0).astype(np.float32)/255\n",
    "        data = data-0.13/0.31\n",
    "        label = label.astype(np.float32)\n",
    "        return data, label\n",
    "\n",
    "    train_dataset = gluon.data.vision.datasets.MNIST(root=M5_IMAGES, train=True, transform=transformer)\n",
    "    validation_dataset = gluon.data.vision.datasets.MNIST(root=M5_IMAGES, train=False, transform=transformer)\n",
    "    train_dataloader = gluon.data.DataLoader(train_dataset, batch_size=batch, last_batch='keep',shuffle=True)\n",
    "    validation_dataloader = gluon.data.DataLoader(validation_dataset, batch_size=batch, last_batch='keep')\n",
    "    \n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v = get_mnist_data()\n",
    "assert isinstance(t, gluon.data.DataLoader)\n",
    "assert isinstance(v, gluon.data.DataLoader)\n",
    "\n",
    "d, l = next(iter(t))\n",
    "assert d.shape == (128, 1, 28, 28) #check Channel First and Batch Size\n",
    "assert l.shape == (128,)\n",
    "\n",
    "assert nd.max(d).asscalar() <= 2.9 # check for normalization\n",
    "assert nd.min(d).asscalar() >= -0.5 # check for normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the training loop\n",
    "\n",
    "* Create the loss function. This should be a loss function suitable for multi-class classification.\n",
    "* Create the metric accumulator. This should the compute and store the accuracy of the model during training\n",
    "* Create the trainer with the `adam` optimizer and learning rate of `0.002`\n",
    "* Write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, training_dataloader, batch_size, epochs):\n",
    "    \"\"\"\n",
    "    Should take an initialized network and train that network using data from the data loader.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param training_dataloader: the training DataLoader provides batches for data for every iteration\n",
    "    :type training_dataloader: gluon.data.DataLoader\n",
    "    \n",
    "    :param batch_size: batch size for the DataLoader.\n",
    "    :type batch_size: int\n",
    "    \n",
    "    :param epochs: number of epochs to train the DataLoader\n",
    "    :type epochs: int\n",
    "    \n",
    "    :return: tuple of trained network and the final training accuracy\n",
    "    :rtype: (gluon.Block, float)\n",
    "    \"\"\"\n",
    "    trainer = gluon.Trainer(network.collect_params(), 'adam',\n",
    "                            {'learning_rate': 0.002})\n",
    "    metric = mx.metric.Accuracy()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss =0.\n",
    "        for data,label in training_dataloader:\n",
    "        \n",
    "#             print (data.shape)\n",
    "#             print (label.shape)\n",
    "            with autograd.record():\n",
    "                output = network(data)\n",
    "                loss=mx.ndarray.softmax_cross_entropy(output,label)\n",
    "            loss.backward()\n",
    "\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += loss.mean().asscalar()\n",
    "            metric.update(label, output)\n",
    "            \n",
    "        print (epoch , metric.get()[1])    \n",
    "        training_accuracy = metric.get()[1]\n",
    "    return network, training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "net.add(gluon.nn.Conv2D(channels=6, kernel_size=5, activation='relu'),\n",
    "        gluon.nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        gluon.nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "        gluon.nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        gluon.nn.Flatten(),\n",
    "        gluon.nn.Dense(120, activation=\"relu\"),\n",
    "        gluon.nn.Dense(84, activation=\"relu\"),\n",
    "        gluon.nn.Dense(10))\n",
    "net.initialize(init=init.Xavier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9357833333333333\n",
      "1 0.9584583333333333\n",
      "2 0.9677\n",
      "3 0.9729708333333333\n",
      "4 0.97662\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "n, ta = train(net, t, 128, 5)\n",
    "assert ta >= .95\n",
    "\n",
    "d, l = next(iter(v))\n",
    "p = (n(d).argmax(axis=1))\n",
    "assert (p.asnumpy() == l.asnumpy()).sum()/128.0 > .95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the validation loop\n",
    "\n",
    "* Create the metric accumulator. This should the compute and store the accuracy of the model on the validation set\n",
    "* Write the validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(network, validation_dataloader):\n",
    "    \"\"\"\n",
    "    Should compute the accuracy of the network on the validation set.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param validation_dataloader: the training DataLoader provides batches for data for every iteration\n",
    "    :type validation_dataloader: gluon.data.DataLoader\n",
    "    \n",
    "    :return: validation accuracy\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    val_acc = mx.metric.Accuracy()\n",
    "    for data,label in validation_dataloader:\n",
    "        output = network(data)\n",
    "        val_acc.update(label,output)\n",
    "    print (val_acc.get()[1])\n",
    "    return val_acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988\n"
     ]
    }
   ],
   "source": [
    "assert validate(n, v) > .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
